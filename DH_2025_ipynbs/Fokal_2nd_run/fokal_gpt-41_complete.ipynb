{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bc81648-c397-4845-b2b6-873c4b0eb7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.61.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (2.10.4)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7141783-7817-4e7c-ad1e-50fe75cf6dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "from statsmodels.stats.contingency_tables import mcnemar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66fbceb6-a14f-47f3-b08c-86a1595a093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89314e97-8eaf-49cc-9246-c86e4f09d2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df995423-2177-4863-91db-5c5b4b74964c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87645a4f-3173-4566-9640-8cb7cec1faa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a628383-5a13-4bfc-9df4-b067b6ec4dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anno = pd.read_csv('plasticity_2025_Anno_DEU_test_2nd_run.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82bccc58-19d7-4456-8178-09093d414624",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anno['Fokalisierung'] = df_anno['Fokalisierung'].replace({\n",
    "    'intern': 'internal',\n",
    "    'extern': 'external',\n",
    "    'null': 'zero',\n",
    "    None: 'zero',\n",
    "    np.nan: 'zero'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a872635-ea48-4780-9256-9e983ea3a99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Autor</th>\n",
       "      <th>Titel</th>\n",
       "      <th>Absatz</th>\n",
       "      <th>Fokalisierung</th>\n",
       "      <th>Kommentar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Schiller</td>\n",
       "      <td>Der Vebrecher aus verlorener Ehre</td>\n",
       "      <td>In der ganzen Geschichte des Menschen ist kein...</td>\n",
       "      <td>zero</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Schiller</td>\n",
       "      <td>Der Vebrecher aus verlorener Ehre</td>\n",
       "      <td>Es ist etwas so Einförmiges und doch wieder so...</td>\n",
       "      <td>zero</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Schiller</td>\n",
       "      <td>Der Vebrecher aus verlorener Ehre</td>\n",
       "      <td>Ich weiß, daß von den besten Geschichtschreibe...</td>\n",
       "      <td>internal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Schiller</td>\n",
       "      <td>Der Vebrecher aus verlorener Ehre</td>\n",
       "      <td>Der Held muß kalt werden wie der Leser, oder, ...</td>\n",
       "      <td>zero</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tieck</td>\n",
       "      <td>Die beiden merkwürdigsten Tage aus Siegmunds L...</td>\n",
       "      <td>Es war schon gegen Abend, als ein Wagen vor de...</td>\n",
       "      <td>internal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Autor                                              Titel  \\\n",
       "0  Schiller                  Der Vebrecher aus verlorener Ehre   \n",
       "1  Schiller                  Der Vebrecher aus verlorener Ehre   \n",
       "2  Schiller                  Der Vebrecher aus verlorener Ehre   \n",
       "3  Schiller                  Der Vebrecher aus verlorener Ehre   \n",
       "4     Tieck  Die beiden merkwürdigsten Tage aus Siegmunds L...   \n",
       "\n",
       "                                              Absatz Fokalisierung  Kommentar  \n",
       "0  In der ganzen Geschichte des Menschen ist kein...          zero        NaN  \n",
       "1  Es ist etwas so Einförmiges und doch wieder so...          zero        NaN  \n",
       "2  Ich weiß, daß von den besten Geschichtschreibe...      internal        NaN  \n",
       "3  Der Held muß kalt werden wie der Leser, oder, ...          zero        NaN  \n",
       "4  Es war schon gegen Abend, als ein Wagen vor de...      internal        NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3fbefde-5a2a-4237-a347-9eea73e9befb",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv('MY_OPENAI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c641fbf-c363-4333-b161-c9ef54003893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt):  \n",
    "    client = OpenAI(api_key=api_key)\n",
    "    response = client.chat.completions.create(\n",
    "        temperature = 0.1,\n",
    "        messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt,\n",
    "        }],\n",
    "        model=\"gpt-4.1-2025-04-14\",\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4801e14-5434-4239-b884-5392bd6bf1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_basic = \"\"\"\n",
    "### Instruction\n",
    "Your task is to classify the focalization of the following sentence\n",
    "\n",
    "###\n",
    "Only respond with one word representing the mode of focalization, do NOT give explenations or generate more text \n",
    "Sentence: '''{text}''''\n",
    "Label:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f88bc732-1ab7-4c8e-9ca2-d6659a271388",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_labels = \"\"\"\n",
    "### Instruction\n",
    "Your task is to classify the focalization of the following sentence\n",
    "\n",
    "### Labels\n",
    "There are three modes of focalization:\n",
    "- internal\n",
    "- external\n",
    "- zero\n",
    "\n",
    "####\n",
    "Only respond with one word representing the mode of focalization, do NOT give explenations or generate more text \n",
    "Sentence: '''{text}''' \n",
    "Label: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a28efea-cd61-4b50-8e9b-8cf27d39daf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_redefin = \"\"\"\n",
    "### Instruction\n",
    "Your task is to classify the focalization of the following sentence\n",
    "\n",
    "### Labels\n",
    "There are three modes of focalization:\n",
    "- internal: A text passage is internally focalized precisely when a perceptual process is part of the depicted event and is presented from the perspective of a character.\n",
    "- external: A text passage is externally focalized precisely when a perceptual process is part of the depicted event and could be presented from the perspective of a character.\n",
    "- zero: A text passage is zero focalized precisely when circumstances of the narrated world are described as if they were independent of a particular perceptual process of a person or are not possible for a person to perceive synchronously.\n",
    "\n",
    "####\n",
    "Only respond with one word representing the mode of focalization, do NOT give explenations or generate more text  \n",
    "Sentence: '''{text}''' \n",
    "Label: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73534894-2a90-40b2-acc4-d81a9abab0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_meta = \"\"\"\n",
    "### Instruction\n",
    "Your task is to classify the focalization of the following sentence\n",
    "\n",
    "### Labels\n",
    "There are three modes of focalization:\n",
    "- internal: A text passage is internally focalized precisely when a perceptual process is part of the depicted event and is presented from the perspective of a character.\n",
    "- external: A text passage is externally focalized precisely when a perceptual process is part of the depicted event and could be presented from the perspective of a character.\n",
    "- zero: A text passage is zero focalized precisely when circumstances of the narrated world are described as if they were independent of a particular perceptual process of a person or are not possible for a person to perceive synchronously. \n",
    "These definitions are redefinitions of the standard understanding of focalization.\n",
    "\n",
    "####\n",
    "Only respond with one word representing the mode of focalization, do NOT give explenations or generate more text \n",
    "Sentence: '''{text}''' \n",
    "Label: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7aedc23c-95fb-41e6-8f42-4bc779f5c3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_templates = [prompt_labels, prompt_redefin, prompt_meta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbc03d8f-dc77-4569-bb48-b131a98d65d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prompts_and_predictions(df, prompt_templates):\n",
    "    \"\"\"\n",
    "    Evaluiert verschiedene Prompt-Templates und berechnet Metriken für die Vorhersagen.\n",
    "    Jeder Prompt wird zweimal über die Daten ausgeführt.\n",
    "    \n",
    "    Args:\n",
    "        df: Pandas DataFrame mit den Spalten 'Absatz' und 'Fokalisierung'\n",
    "        prompt_templates: Liste der Prompt-Templates\n",
    "    \n",
    "    Returns:\n",
    "        Tuple mit:\n",
    "            - df: DataFrame mit den gespeicherten Vorhersagen\n",
    "            - results_df: DataFrame mit den Evaluierungsmetriken für jeden Prompt und jeden Run\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for run in range(1, 6):\n",
    "        print(f\"Starte Run {run}/5\")\n",
    "\n",
    "        # Iteration über die Prompt-Templates\n",
    "        for prompt_idx, template in enumerate(prompt_templates):\n",
    "            print(f\"Verarbeite Prompt-Template {prompt_idx + 1}/{len(prompt_templates)} - Run {run}\")\n",
    "            \n",
    "            # Spaltenname für Vorhersage definieren\n",
    "            prediction_col = f'Prediction_{prompt_idx}_Run{run}'\n",
    "            df[prediction_col] = None\n",
    "            \n",
    "            # Iteration über die Zeilen des DataFrames\n",
    "            for idx, row in df.iterrows():\n",
    "                prompt = template.format(text=row['Absatz'])\n",
    "                prediction = get_completion(prompt)\n",
    "                first_word = prediction.split()[0].lower()\n",
    "                print(first_word)\n",
    "                df.at[idx, prediction_col] = first_word\n",
    "            \n",
    "            # Metriken berechnen\n",
    "            metrics = {\n",
    "                'Prompt': f'Template_{prompt_idx}',\n",
    "                'Run': run,\n",
    "                'F1-Score': f1_score(df['Fokalisierung'], df[prediction_col], average='weighted'),\n",
    "                'Recall': recall_score(df['Fokalisierung'], df[prediction_col], average='weighted'),\n",
    "                'Precision': precision_score(df['Fokalisierung'], df[prediction_col], average='weighted'),\n",
    "                'Accuracy': accuracy_score(df['Fokalisierung'], df[prediction_col])\n",
    "            }\n",
    "            \n",
    "            results.append(metrics)\n",
    "    \n",
    "    # Ergebnisse in DataFrame umwandeln\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return df, results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35569bc4-db87-4563-99b3-3c0b21a5cdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Run 1/5\n",
      "Verarbeite Prompt-Template 1/3 - Run 1\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "external\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "external\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "external\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "external\n",
      "internal\n",
      "internal\n",
      "external\n",
      "external\n",
      "external\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "Verarbeite Prompt-Template 2/3 - Run 1\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "Verarbeite Prompt-Template 3/3 - Run 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "Starte Run 2/5\n",
      "Verarbeite Prompt-Template 1/3 - Run 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "external\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "external\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "external\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "external\n",
      "external\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "Verarbeite Prompt-Template 2/3 - Run 2\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "Verarbeite Prompt-Template 3/3 - Run 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "Starte Run 3/5\n",
      "Verarbeite Prompt-Template 1/3 - Run 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "external\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "external\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "external\n",
      "external\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "Verarbeite Prompt-Template 2/3 - Run 3\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "Verarbeite Prompt-Template 3/3 - Run 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "Starte Run 4/5\n",
      "Verarbeite Prompt-Template 1/3 - Run 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "external\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "external\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "external\n",
      "external\n",
      "external\n",
      "external\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "Verarbeite Prompt-Template 2/3 - Run 4\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "Verarbeite Prompt-Template 3/3 - Run 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "Starte Run 5/5\n",
      "Verarbeite Prompt-Template 1/3 - Run 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "external\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "external\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "external\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "external\n",
      "external\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "Verarbeite Prompt-Template 2/3 - Run 5\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "Verarbeite Prompt-Template 3/3 - Run 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "results_gpt41, test = evaluate_prompts_and_predictions(df_anno, prompt_templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83ce21fc-ec21-40fc-8f28-a01efcf96cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gpt41.to_json(\"DH_gpt41_results\", orient=\"records\", indent=4, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfce498a-b205-4602-af89-f8debe982b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Run</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Template_0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.689562</td>\n",
       "      <td>0.707547</td>\n",
       "      <td>0.747109</td>\n",
       "      <td>0.707547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Template_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.639240</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.579619</td>\n",
       "      <td>0.716981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Template_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.613891</td>\n",
       "      <td>0.688679</td>\n",
       "      <td>0.558872</td>\n",
       "      <td>0.688679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Template_0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.660458</td>\n",
       "      <td>0.688679</td>\n",
       "      <td>0.728867</td>\n",
       "      <td>0.688679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Template_1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.646994</td>\n",
       "      <td>0.726415</td>\n",
       "      <td>0.586201</td>\n",
       "      <td>0.726415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Template_2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.613891</td>\n",
       "      <td>0.688679</td>\n",
       "      <td>0.558872</td>\n",
       "      <td>0.688679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Template_0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.652996</td>\n",
       "      <td>0.688679</td>\n",
       "      <td>0.726161</td>\n",
       "      <td>0.688679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Template_1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.622126</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.562984</td>\n",
       "      <td>0.698113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Template_2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.613891</td>\n",
       "      <td>0.688679</td>\n",
       "      <td>0.558872</td>\n",
       "      <td>0.688679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Template_0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.682550</td>\n",
       "      <td>0.707547</td>\n",
       "      <td>0.749724</td>\n",
       "      <td>0.707547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Template_1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.606362</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.555559</td>\n",
       "      <td>0.679245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Template_2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.630384</td>\n",
       "      <td>0.707547</td>\n",
       "      <td>0.573667</td>\n",
       "      <td>0.707547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Template_0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.652051</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.723547</td>\n",
       "      <td>0.679245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Template_1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.630446</td>\n",
       "      <td>0.707547</td>\n",
       "      <td>0.571383</td>\n",
       "      <td>0.707547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Template_2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.613891</td>\n",
       "      <td>0.688679</td>\n",
       "      <td>0.558872</td>\n",
       "      <td>0.688679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Prompt  Run  F1-Score    Recall  Precision  Accuracy\n",
       "0   Template_0    1  0.689562  0.707547   0.747109  0.707547\n",
       "1   Template_1    1  0.639240  0.716981   0.579619  0.716981\n",
       "2   Template_2    1  0.613891  0.688679   0.558872  0.688679\n",
       "3   Template_0    2  0.660458  0.688679   0.728867  0.688679\n",
       "4   Template_1    2  0.646994  0.726415   0.586201  0.726415\n",
       "5   Template_2    2  0.613891  0.688679   0.558872  0.688679\n",
       "6   Template_0    3  0.652996  0.688679   0.726161  0.688679\n",
       "7   Template_1    3  0.622126  0.698113   0.562984  0.698113\n",
       "8   Template_2    3  0.613891  0.688679   0.558872  0.688679\n",
       "9   Template_0    4  0.682550  0.707547   0.749724  0.707547\n",
       "10  Template_1    4  0.606362  0.679245   0.555559  0.679245\n",
       "11  Template_2    4  0.630384  0.707547   0.573667  0.707547\n",
       "12  Template_0    5  0.652051  0.679245   0.723547  0.679245\n",
       "13  Template_1    5  0.630446  0.707547   0.571383  0.707547\n",
       "14  Template_2    5  0.613891  0.688679   0.558872  0.688679"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "311774ab-adc4-40e2-b4f7-cf99956d01e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_prompt_metrics(df):\n",
    "    summary_rows = []\n",
    "\n",
    "    # Gruppieren nach Prompt-Template\n",
    "    grouped = df.groupby(\"Prompt\")\n",
    "\n",
    "    for prompt, group in grouped:\n",
    "        f1_median = group[\"F1-Score\"].median()\n",
    "        f1_min = group[\"F1-Score\"].min()\n",
    "        f1_max = group[\"F1-Score\"].max()\n",
    "\n",
    "        precision_mean = group[\"Precision\"].mean()\n",
    "        precision_std = group[\"Precision\"].std()\n",
    "\n",
    "        recall_mean = group[\"Recall\"].mean()\n",
    "        recall_std = group[\"Recall\"].std()\n",
    "\n",
    "        acc_mean = group[\"Accuracy\"].mean()\n",
    "        acc_std = group[\"Accuracy\"].std()\n",
    "\n",
    "        summary_rows.append({\n",
    "            \"Prompt\": prompt,\n",
    "            \"F1-Median (Min–Max)\": f\"{f1_median:.3f} ({f1_min:.3f}–{f1_max:.3f})\",\n",
    "            \"Precision (M ± SD)\": f\"{precision_mean:.3f} ± {precision_std:.3f}\",\n",
    "            \"Recall (M ± SD)\": f\"{recall_mean:.3f} ± {recall_std:.3f}\",\n",
    "            \"Accuracy (M ± SD)\": f\"{acc_mean:.3f} ± {acc_std:.3f}\",\n",
    "        })\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "    return summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f197c2a9-6889-4a8f-ad44-03832b73058d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>F1-Median (Min–Max)</th>\n",
       "      <th>Precision (M ± SD)</th>\n",
       "      <th>Recall (M ± SD)</th>\n",
       "      <th>Accuracy (M ± SD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Template_0</td>\n",
       "      <td>0.660 (0.652–0.690)</td>\n",
       "      <td>0.735 ± 0.012</td>\n",
       "      <td>0.694 ± 0.013</td>\n",
       "      <td>0.694 ± 0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Template_1</td>\n",
       "      <td>0.630 (0.606–0.647)</td>\n",
       "      <td>0.571 ± 0.012</td>\n",
       "      <td>0.706 ± 0.018</td>\n",
       "      <td>0.706 ± 0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Template_2</td>\n",
       "      <td>0.614 (0.614–0.630)</td>\n",
       "      <td>0.562 ± 0.007</td>\n",
       "      <td>0.692 ± 0.008</td>\n",
       "      <td>0.692 ± 0.008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Prompt  F1-Median (Min–Max) Precision (M ± SD) Recall (M ± SD)  \\\n",
       "0  Template_0  0.660 (0.652–0.690)      0.735 ± 0.012   0.694 ± 0.013   \n",
       "1  Template_1  0.630 (0.606–0.647)      0.571 ± 0.012   0.706 ± 0.018   \n",
       "2  Template_2  0.614 (0.614–0.630)      0.562 ± 0.007   0.692 ± 0.008   \n",
       "\n",
       "  Accuracy (M ± SD)  \n",
       "0     0.694 ± 0.013  \n",
       "1     0.706 ± 0.018  \n",
       "2     0.692 ± 0.008  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = summarize_prompt_metrics(test)\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bbc3ba-2dc0-42e0-ac26-5566f2b0d569",
   "metadata": {},
   "source": [
    "## Optimization – DSPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5657245b-0afb-4f81-b8d8-b95179272266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "476a0ad6-1a04-4187-8d44-49f550e631c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "293a40ef-3264-4f66-82b0-25e14045eb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "litellm.drop_params = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb619f4-15b7-4a05-8474-e6a3d83db1dc",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f93b4b27-de72-4dc6-a369-9951489e8a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anno_train = pd.read_csv('plasticity_focalization_trainset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b22c9d49-c250-4b0b-8d00-e57a5b32c2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anno_train['Fokalisierung'] = df_anno_train['Fokalisierung'].replace({\n",
    "    'intern': 'internal',\n",
    "    'extern': 'external',\n",
    "    'null': 'zero',\n",
    "    None: 'zero',\n",
    "    np.nan: 'zero'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "794d21a8-e57f-4ad5-9b54-a4c39dc47c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anno_test = pd.read_csv('plasticity_2025_Anno_DEU_test_2nd_run.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06e5dac2-c06a-48c5-b510-fb59346f2989",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anno_test['Fokalisierung'] = df_anno_test['Fokalisierung'].replace({\n",
    "    'intern': 'internal',\n",
    "    'extern': 'external',\n",
    "    'null': 'zero',\n",
    "    None: 'zero',\n",
    "    np.nan: 'zero'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ffab7af0-37c1-4970-8e24-11ee86f8b61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Autor</th>\n",
       "      <th>Titel</th>\n",
       "      <th>Absatz</th>\n",
       "      <th>Fokalisierung</th>\n",
       "      <th>Kommentar</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Goethe</td>\n",
       "      <td>Die Sängerin Antonelli</td>\n",
       "      <td>Als ich mich in Neapel aufhielt, begegnete das...</td>\n",
       "      <td>internal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.projekt-gutenberg.org/goethe/anton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Goethe</td>\n",
       "      <td>Die Sängerin Antonelli</td>\n",
       "      <td>Eine Sängerin, Antonelli genannt, war zu meine...</td>\n",
       "      <td>internal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.projekt-gutenberg.org/goethe/anton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Goethe</td>\n",
       "      <td>Die Sängerin Antonelli</td>\n",
       "      <td>Bei ihren bisherigen Verbindungen war ihr Geis...</td>\n",
       "      <td>internal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.projekt-gutenberg.org/goethe/anton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Goethe</td>\n",
       "      <td>Die Sängerin Antonelli</td>\n",
       "      <td>Es war ein Genueser, der sich um diese Zeit ei...</td>\n",
       "      <td>internal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.projekt-gutenberg.org/goethe/anton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tieck</td>\n",
       "      <td>Das grüne Band</td>\n",
       "      <td>Durch die Thäler und über die Wiesen wandelte ...</td>\n",
       "      <td>external</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.projekt-gutenberg.org/tieck/grueba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Autor                   Titel  \\\n",
       "0  Goethe  Die Sängerin Antonelli   \n",
       "1  Goethe  Die Sängerin Antonelli   \n",
       "2  Goethe  Die Sängerin Antonelli   \n",
       "3  Goethe  Die Sängerin Antonelli   \n",
       "4   Tieck          Das grüne Band   \n",
       "\n",
       "                                              Absatz Fokalisierung Kommentar  \\\n",
       "0  Als ich mich in Neapel aufhielt, begegnete das...      internal       NaN   \n",
       "1  Eine Sängerin, Antonelli genannt, war zu meine...      internal       NaN   \n",
       "2  Bei ihren bisherigen Verbindungen war ihr Geis...      internal       NaN   \n",
       "3  Es war ein Genueser, der sich um diese Zeit ei...      internal       NaN   \n",
       "4  Durch die Thäler und über die Wiesen wandelte ...      external       NaN   \n",
       "\n",
       "                                                Link  \n",
       "0  https://www.projekt-gutenberg.org/goethe/anton...  \n",
       "1  https://www.projekt-gutenberg.org/goethe/anton...  \n",
       "2  https://www.projekt-gutenberg.org/goethe/anton...  \n",
       "3  https://www.projekt-gutenberg.org/goethe/anton...  \n",
       "4  https://www.projekt-gutenberg.org/tieck/grueba...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anno_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54b3959a-d89c-4605-88b2-1f5731f4e651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_sample_by_category(df, category_column, n_per_category=8, random_state=42):\n",
    "    \"\"\"\n",
    "    Gibt ein balanciertes Sample aus dem DataFrame zurück mit n_per_category Einträgen pro Kategorie.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Eingabedaten.\n",
    "        category_column (str): Spaltenname, nach dem kategorisiert werden soll.\n",
    "        n_per_category (int): Anzahl von Einträgen pro Kategorie.\n",
    "        random_state (int): Seed für Reproduzierbarkeit.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Balanciertes Sample.\n",
    "    \"\"\"\n",
    "    # Fehlende Kategorien ausschließen\n",
    "    df_clean = df.dropna(subset=[category_column])\n",
    "\n",
    "    # Alle eindeutigen Kategorien abrufen\n",
    "    categories = df_clean[category_column].unique()\n",
    "\n",
    "    # Sampling durchführen\n",
    "    balanced_df = pd.concat([\n",
    "        df_clean[df_clean[category_column] == cat].sample(\n",
    "            n=min(n_per_category, len(df_clean[df_clean[category_column] == cat])),\n",
    "            random_state=random_state\n",
    "        )\n",
    "        for cat in categories\n",
    "    ])\n",
    "\n",
    "    # Index zurücksetzen\n",
    "    return balanced_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "709ba742-ea98-4908-8ed4-2846b724f0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_balanced = balanced_sample_by_category(df_anno_train, category_column=\"Fokalisierung\", n_per_category=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77693eea-4e7e-4726-84f4-af689bdda0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Autor</th>\n",
       "      <th>Titel</th>\n",
       "      <th>Absatz</th>\n",
       "      <th>Fokalisierung</th>\n",
       "      <th>Kommentar</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Brentano</td>\n",
       "      <td>Baron Hüpfenstich</td>\n",
       "      <td>Als ich mich in Neapel aufhielt, begegnete das...</td>\n",
       "      <td>internal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.projekt-gutenberg.org/brentano/hue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Autor              Titel  \\\n",
       "count         24                 24   \n",
       "unique        14                 14   \n",
       "top     Brentano  Baron Hüpfenstich   \n",
       "freq           3                  3   \n",
       "\n",
       "                                                   Absatz Fokalisierung  \\\n",
       "count                                                  24            24   \n",
       "unique                                                 24             3   \n",
       "top     Als ich mich in Neapel aufhielt, begegnete das...      internal   \n",
       "freq                                                    1             8   \n",
       "\n",
       "       Kommentar                                               Link  \n",
       "count          0                                                 24  \n",
       "unique         0                                                 14  \n",
       "top          NaN  https://www.projekt-gutenberg.org/brentano/hue...  \n",
       "freq         NaN                                                  3  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_balanced.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48206cf4-b5fa-4e41-a542-69a4c7455ab4",
   "metadata": {},
   "source": [
    "# Preparing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159480a8-fbc7-4268-b446-d4b8a106add8",
   "metadata": {},
   "source": [
    "Anleitung zur Erstellung eines Datensets: https://dspy-docs.vercel.app/docs/deep-dive/data-handling/loading-custom-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8876547-599e-4408-97f8-ec7440eb0190",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.datasets.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d0226e21-18c3-4d8c-9fb8-30464f2d7e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_train_balanced[[\"Absatz\", \"Fokalisierung\"]].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aaba2e55-d87d-464e-a6aa-052361263e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Absatz</th>\n",
       "      <th>Fokalisierung</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Als ich mich in Neapel aufhielt, begegnete das...</td>\n",
       "      <td>internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eine große Sorge hatte der gute König jetzt, d...</td>\n",
       "      <td>internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Es ist doch etwas Schönes, Herrliches, Erhaben...</td>\n",
       "      <td>internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eine Sängerin, Antonelli genannt, war zu meine...</td>\n",
       "      <td>internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Einen anderen Weg schlag ich ein; er ist aller...</td>\n",
       "      <td>internal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Absatz Fokalisierung\n",
       "0  Als ich mich in Neapel aufhielt, begegnete das...      internal\n",
       "1  Eine große Sorge hatte der gute König jetzt, d...      internal\n",
       "2  Es ist doch etwas Schönes, Herrliches, Erhaben...      internal\n",
       "3  Eine Sängerin, Antonelli genannt, war zu meine...      internal\n",
       "4  Einen anderen Weg schlag ich ein; er ist aller...      internal"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da82bc02-7afa-4547-84fa-a42848870cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8351645-e105-40ff-bb33-f0d9733a6879",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, df, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        df=df\n",
    "        #self._train = df.iloc[0:35].to_dict(orient='records')\n",
    "        self._dev = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e377cbcc-631f-46da-a617-0913b46bd0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CSVDataset(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "671b5ee3-fc6c-4405-90f8-195267a2b8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270fd88a-849e-4ebe-ac09-fce57f73a6b2",
   "metadata": {},
   "source": [
    "# Setting LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a2f5a86-845b-4ae0-ba2a-f765f9a7ae25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.settings.configure(\n",
    "    cache=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "48236fa5-07ce-4587-9bcc-2a8438f063b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_key = os.getenv('MY_OPENAI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99ed75b8-413a-4e64-8716-ecc638ac951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = dspy.LM('gpt-4.1-2025-04-14', api_key=gpt_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d5a3f6c-50c5-429c-8335-55ea62507499",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.settings.configure(lm=gpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aac1bbe-afe5-4326-9e71-8d7078ea6cd5",
   "metadata": {},
   "source": [
    "# Setting Up Module + checking output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8449e51e-76fa-44ce-a665-17b8302b9631",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Determinacy(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Your task is to classify the focalization of the following sentence \n",
    "    \n",
    "    ### Labels\n",
    "    There are three modes of focalization:\n",
    "    - internal: A text passage is internally focalized precisely when a perceptual process is part of the depicted event and is presented from the perspective of a character.\n",
    "    - external: A text passage is externally focalized precisely when a perceptual process is part of the depicted event and could be presented from the perspective of a character.\n",
    "    - zero: A text passage is zero focalized precisely when circumstances of the narrated world are described as if they were independent of a particular perceptual process of a person or are not possible for a person to perceive synchronously.\n",
    "    \"\"\"\n",
    "    #context = dspy.InputField(desc=\"contains annotation guidelines and scoring instructions\")\n",
    "    text_snippet = dspy.InputField(desc=\"contains a snippet of a narrative text\")\n",
    "    tag = dspy.OutputField(desc=\"contains only the **label** in lower case\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5aa19ddd-2948-47e8-a20c-2f7c4fa3996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\" \n",
    "### Labels\n",
    "There are three modes of focalization:\n",
    "- internal: A text passage is internally focalized precisely when a perceptual process is part of the depicted event and is presented from the perspective of a character.\n",
    "- external: A text passage is externally focalized precisely when a perceptual process is part of the depicted event and could be presented from the perspective of a character.\n",
    "- zero: A text passage is zero focalized precisely when circumstances of the narrated world are described as if they were independent of a particular perceptual process of a person or are not possible for a person to perceive synchronously.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c0466-5233-40ea-af5d-f2c284cd0843",
   "metadata": {},
   "source": [
    "# Setting Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e487369-6594-4d31-8285-5f74a7981d69",
   "metadata": {},
   "source": [
    "Anleitung zu den Metriken in DSPY: https://dspy-docs.vercel.app/docs/building-blocks/metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f9da47d-2c28-4459-aa32-b5faa564d54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.evaluate import Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "60b882d7-d032-4325-9116-657de4686c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_tag(example, pred, trace=None):\n",
    "    print(example.answer)\n",
    "    print(pred.tag)\n",
    "    return example.answer in pred.tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ca602e-6cbe-4b66-b31e-5404ca580748",
   "metadata": {},
   "source": [
    "# Trying out the Signature Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16518f80-8f2c-46af-9a75-db13e5a840d3",
   "metadata": {},
   "source": [
    "Anleitung zur Arbeit mit dem Optimizer bei zero-shot: https://dspy-docs.vercel.app/docs/deep-dive/teleprompter/signature-optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6bfe03b-7e72-45ac-9351-d8c3ca965d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeterminacyPipe(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.signature = Determinacy\n",
    "        self.predictor = dspy.ChainOfThought(self.signature)\n",
    "        \n",
    "    def forward(self, text_snippet):\n",
    "        result = self.predictor(text_snippet=text_snippet)\n",
    "        return dspy.Prediction(\n",
    "            tag = result.tag\n",
    "        )      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d0fb1a62-2125-45c6-973d-e38d5768c72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "devset = dataset.dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0b0d3149-c78f-4317-b7e7-e565d9dadc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = Evaluate(devset=devset, metric=validate_tag, num_threads=3, display_progress=True, display_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ada22b2d-309f-46ff-9fae-8f83b5b78d1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "event_baseline = DeterminacyPipe()\n",
    "devset_with_input = [dspy.Example({\"text_snippet\": r[\"Absatz\"], \"answer\": r[\"Fokalisierung\"]}).with_inputs(\"context\", \"text_snippet\") for r in devset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "209115b7-024f-4b14-8803-73bf8fe76dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "internal                                                 | 0/24 [00:00<?, ?it/s]\n",
      "internal\n",
      "externalMetric: 1.00 / 1 (100.0%):   4%|▍        | 1/24 [00:04<01:32,  4.02s/it]\n",
      "internal\n",
      "zeroage Metric: 1.00 / 2 (50.0%):   8%|▊         | 2/24 [00:05<00:53,  2.42s/it]\n",
      "zero\n",
      "externalMetric: 2.00 / 3 (66.7%):  12%|█▎        | 3/24 [00:06<00:40,  1.94s/it]\n",
      "zero\n",
      "internalMetric: 2.00 / 4 (50.0%):  17%|█▋        | 4/24 [00:09<00:46,  2.30s/it]\n",
      "internal\n",
      "internalMetric: 3.00 / 5 (60.0%):  21%|██        | 5/24 [00:12<00:46,  2.47s/it]\n",
      "internal\n",
      "zeroage Metric: 4.00 / 6 (66.7%):  25%|██▌       | 6/24 [00:14<00:40,  2.23s/it]\n",
      "zero\n",
      "externalMetric: 5.00 / 7 (71.4%):  29%|██▉       | 7/24 [00:16<00:37,  2.18s/it]\n",
      "zero\n",
      "zeroage Metric: 5.00 / 8 (62.5%):  33%|███▎      | 8/24 [00:16<00:27,  1.74s/it]\n",
      "zero\n",
      "internalMetric: 6.00 / 9 (66.7%):  38%|███▊      | 9/24 [00:17<00:18,  1.25s/it]\n",
      "internal\n",
      "internalMetric: 7.00 / 10 (70.0%):  42%|███▎    | 10/24 [00:18<00:19,  1.42s/it]\n",
      "internal\n",
      "zeroage Metric: 8.00 / 11 (72.7%):  46%|███▋    | 11/24 [00:19<00:16,  1.31s/it]\n",
      "internal\n",
      "internalMetric: 8.00 / 12 (66.7%):  50%|████    | 12/24 [00:20<00:13,  1.16s/it]\n",
      "internal\n",
      "internalMetric: 9.00 / 13 (69.2%):  54%|████▎   | 13/24 [00:23<00:17,  1.58s/it]\n",
      "internal\n",
      "zeroage Metric: 10.00 / 14 (71.4%):  58%|████   | 14/24 [00:25<00:16,  1.62s/it]\n",
      "internal\n",
      "zeroage Metric: 10.00 / 15 (66.7%):  58%|████   | 14/24 [00:25<00:16,  1.62s/it]\n",
      "internal\n",
      "externalMetric: 10.00 / 16 (62.5%):  67%|████▋  | 16/24 [00:26<00:09,  1.14s/it]\n",
      "internal\n",
      "externalMetric: 10.00 / 17 (58.8%):  71%|████▉  | 17/24 [00:28<00:09,  1.34s/it]\n",
      "external\n",
      "zeroage Metric: 11.00 / 18 (61.1%):  75%|█████▎ | 18/24 [00:29<00:08,  1.39s/it]\n",
      "zero\n",
      "zeroage Metric: 12.00 / 19 (63.2%):  75%|█████▎ | 18/24 [00:29<00:08,  1.39s/it]\n",
      "zero\n",
      "internalMetric: 13.00 / 20 (65.0%):  83%|█████▊ | 20/24 [00:32<00:05,  1.43s/it]\n",
      "internal\n",
      "externalMetric: 14.00 / 21 (66.7%):  88%|██████▏| 21/24 [00:32<00:03,  1.17s/it]\n",
      "zero\n",
      "externalMetric: 14.00 / 22 (63.6%):  92%|██████▍| 22/24 [00:33<00:02,  1.06s/it]\n",
      "internal\n",
      "externalMetric: 14.00 / 23 (60.9%):  96%|██████▋| 23/24 [00:35<00:01,  1.23s/it]\n",
      "zero\n",
      "Average Metric: 14.00 / 24 (58.3%): 100%|███████| 24/24 [00:36<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/24 11:08:37 INFO dspy.evaluate.evaluate: Average Metric: 14 / 24 (58.3%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_snippet</th>\n",
       "      <th>answer</th>\n",
       "      <th>tag</th>\n",
       "      <th>validate_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Als der Tag anbrach, noch ehe die Sonne aufgegangen war, kam schon...</td>\n",
       "      <td>external</td>\n",
       "      <td>internal</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Als ich mich in Neapel aufhielt, begegnete daselbst eine Geschicht...</td>\n",
       "      <td>internal</td>\n",
       "      <td>internal</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In den letzten Jahrzehnten ist das Interesse an Hungerkünstlern se...</td>\n",
       "      <td>zero</td>\n",
       "      <td>zero</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wie gesagt, die Hand warf mich wieder zur Erde. Bald darauf erfaßt...</td>\n",
       "      <td>internal</td>\n",
       "      <td>internal</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aber da keine Krankheit in ihm war, so war der Gedanke nicht graue...</td>\n",
       "      <td>internal</td>\n",
       "      <td>internal</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Es blieb daher nur noch die andere Seite neben dem Herrenkreuz, un...</td>\n",
       "      <td>external</td>\n",
       "      <td>zero</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>In M..., einer bedeutenden Stadt im oberen Italien, ließ die verwi...</td>\n",
       "      <td>zero</td>\n",
       "      <td>zero</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Die Jugend, welche die beiden Freunde Aeins und Azwei verband, war...</td>\n",
       "      <td>zero</td>\n",
       "      <td>zero</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wenn man in jenen Tagen ein Ding durch die Fichtau bringen wollte,...</td>\n",
       "      <td>external</td>\n",
       "      <td>zero</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Einen anderen Weg schlag ich ein; er ist allerdings etwas weit, ab...</td>\n",
       "      <td>internal</td>\n",
       "      <td>internal</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Es ist doch etwas Schönes, Herrliches, Erhabenes um das Leben! – »...</td>\n",
       "      <td>internal</td>\n",
       "      <td>internal</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hänsel und Gretel saßen um das Feuer, und als der Mittag kam, aß j...</td>\n",
       "      <td>zero</td>\n",
       "      <td>internal</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Eine Sängerin, Antonelli genannt, war zu meiner Zeit der Liebling ...</td>\n",
       "      <td>internal</td>\n",
       "      <td>internal</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Außer den wechselnden Zuschauern waren auch ständige, vom Publikum...</td>\n",
       "      <td>zero</td>\n",
       "      <td>internal</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Nachdem ich die lange Norderstraße hinaufgestiegen und das Tor err...</td>\n",
       "      <td>internal</td>\n",
       "      <td>internal</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>In dem ehrlichen Lande regierte der König Haltewort, ein sehr gute...</td>\n",
       "      <td>zero</td>\n",
       "      <td>internal</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kaum war der Ritter von seinem Rosse gestiegen, als seine Tochter ...</td>\n",
       "      <td>external</td>\n",
       "      <td>internal</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Dieser gute König hatte eine Tochter, die sehr neugierig war und ü...</td>\n",
       "      <td>zero</td>\n",
       "      <td>zero</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Als sie mitten in den Wald gekommen waren, sprach der Vater: »Nun ...</td>\n",
       "      <td>external</td>\n",
       "      <td>external</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Eine dieser Herausforderungen Gottes bestand darin, sich auf dem T...</td>\n",
       "      <td>zero</td>\n",
       "      <td>zero</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Durch die Thäler und über die Wiesen wandelte der graue Nebel; übe...</td>\n",
       "      <td>external</td>\n",
       "      <td>zero</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Eine große Sorge hatte der gute König jetzt, die plagte ihn sehr, ...</td>\n",
       "      <td>internal</td>\n",
       "      <td>internal</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Der Großwesir schlug seine Arme kreuzweis über die Brust, verneigt...</td>\n",
       "      <td>external</td>\n",
       "      <td>internal</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Dieser Vorschlag, von dem Mann mit den Nägeln und dem Hammer gemac...</td>\n",
       "      <td>external</td>\n",
       "      <td>zero</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             text_snippet  \\\n",
       "0   Als der Tag anbrach, noch ehe die Sonne aufgegangen war, kam schon...   \n",
       "1   Als ich mich in Neapel aufhielt, begegnete daselbst eine Geschicht...   \n",
       "2   In den letzten Jahrzehnten ist das Interesse an Hungerkünstlern se...   \n",
       "3   Wie gesagt, die Hand warf mich wieder zur Erde. Bald darauf erfaßt...   \n",
       "4   Aber da keine Krankheit in ihm war, so war der Gedanke nicht graue...   \n",
       "5   Es blieb daher nur noch die andere Seite neben dem Herrenkreuz, un...   \n",
       "6   In M..., einer bedeutenden Stadt im oberen Italien, ließ die verwi...   \n",
       "7   Die Jugend, welche die beiden Freunde Aeins und Azwei verband, war...   \n",
       "8   Wenn man in jenen Tagen ein Ding durch die Fichtau bringen wollte,...   \n",
       "9   Einen anderen Weg schlag ich ein; er ist allerdings etwas weit, ab...   \n",
       "10  Es ist doch etwas Schönes, Herrliches, Erhabenes um das Leben! – »...   \n",
       "11  Hänsel und Gretel saßen um das Feuer, und als der Mittag kam, aß j...   \n",
       "12  Eine Sängerin, Antonelli genannt, war zu meiner Zeit der Liebling ...   \n",
       "13  Außer den wechselnden Zuschauern waren auch ständige, vom Publikum...   \n",
       "14  Nachdem ich die lange Norderstraße hinaufgestiegen und das Tor err...   \n",
       "15  In dem ehrlichen Lande regierte der König Haltewort, ein sehr gute...   \n",
       "16  Kaum war der Ritter von seinem Rosse gestiegen, als seine Tochter ...   \n",
       "17  Dieser gute König hatte eine Tochter, die sehr neugierig war und ü...   \n",
       "18  Als sie mitten in den Wald gekommen waren, sprach der Vater: »Nun ...   \n",
       "19  Eine dieser Herausforderungen Gottes bestand darin, sich auf dem T...   \n",
       "20  Durch die Thäler und über die Wiesen wandelte der graue Nebel; übe...   \n",
       "21  Eine große Sorge hatte der gute König jetzt, die plagte ihn sehr, ...   \n",
       "22  Der Großwesir schlug seine Arme kreuzweis über die Brust, verneigt...   \n",
       "23  Dieser Vorschlag, von dem Mann mit den Nägeln und dem Hammer gemac...   \n",
       "\n",
       "      answer       tag validate_tag  \n",
       "0   external  internal               \n",
       "1   internal  internal    ✔️ [True]  \n",
       "2       zero      zero    ✔️ [True]  \n",
       "3   internal  internal    ✔️ [True]  \n",
       "4   internal  internal    ✔️ [True]  \n",
       "5   external      zero               \n",
       "6       zero      zero    ✔️ [True]  \n",
       "7       zero      zero    ✔️ [True]  \n",
       "8   external      zero               \n",
       "9   internal  internal    ✔️ [True]  \n",
       "10  internal  internal    ✔️ [True]  \n",
       "11      zero  internal               \n",
       "12  internal  internal    ✔️ [True]  \n",
       "13      zero  internal               \n",
       "14  internal  internal    ✔️ [True]  \n",
       "15      zero  internal               \n",
       "16  external  internal               \n",
       "17      zero      zero    ✔️ [True]  \n",
       "18  external  external    ✔️ [True]  \n",
       "19      zero      zero    ✔️ [True]  \n",
       "20  external      zero               \n",
       "21  internal  internal    ✔️ [True]  \n",
       "22  external  internal               \n",
       "23  external      zero               "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "58.33"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(event_baseline, devset=devset_with_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826d0f76-7aed-400a-9052-77fb6d8a4c5f",
   "metadata": {},
   "source": [
    "# Using Copro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c0a3cb2-2075-4266-80e7-e193edc1eff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import COPRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "649e46e5-ebe1-4c73-ae26-406df4f02c8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "teleprompter = dspy.teleprompt.COPRO(\n",
    "    program_mode=\"basic\",\n",
    "    init_temperature=0.4,  \n",
    "    breadth=4,\n",
    "    metric=validate_tag,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "43672ab7-bafe-4699-ab42-ca1477d87177",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/24 11:08:45 INFO dspy.teleprompt.copro_optimizer: Iteration Depth: 1/3.\n",
      "2025/04/24 11:08:45 INFO dspy.teleprompt.copro_optimizer: At Depth 1/3, Evaluating Prompt Candidate #1/4 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "internal                                                 | 0/24 [00:00<?, ?it/s]\n",
      "internal\n",
      "internalMetric: 1.00 / 1 (100.0%):   4%|▍        | 1/24 [00:04<01:49,  4.78s/it]\n",
      "internal\n",
      "internalMetric: 2.00 / 2 (100.0%):   8%|▊        | 2/24 [00:05<00:47,  2.17s/it]\n",
      "internal\n",
      "externalMetric: 3.00 / 3 (100.0%):   8%|▊        | 2/24 [00:05<00:47,  2.17s/it]\n",
      "internal\n",
      "zeroage Metric: 3.00 / 4 (75.0%):  17%|█▋        | 4/24 [00:05<00:20,  1.01s/it]\n",
      "zero\n",
      "externalMetric: 4.00 / 5 (80.0%):  21%|██        | 5/24 [00:05<00:13,  1.37it/s]\n",
      "zero\n",
      "internalMetric: 4.00 / 6 (66.7%):  25%|██▌       | 6/24 [00:08<00:22,  1.22s/it]\n",
      "internal\n",
      "externalMetric: 5.00 / 7 (71.4%):  29%|██▉       | 7/24 [00:08<00:16,  1.01it/s]\n",
      "zero\n",
      "internalMetric: 5.00 / 8 (62.5%):  33%|███▎      | 8/24 [00:08<00:11,  1.35it/s]\n",
      "internal\n",
      "internalMetric: 6.00 / 9 (66.7%):  38%|███▊      | 9/24 [00:11<00:19,  1.33s/it]\n",
      "internal\n",
      "zeroage Metric: 7.00 / 10 (70.0%):  42%|███▎    | 10/24 [00:12<00:16,  1.15s/it]\n",
      "zero\n",
      "internalMetric: 8.00 / 11 (72.7%):  46%|███▋    | 11/24 [00:12<00:13,  1.02s/it]\n",
      "internal\n",
      "zeroage Metric: 9.00 / 12 (75.0%):  50%|████    | 12/24 [00:15<00:18,  1.55s/it]\n",
      "zero\n",
      "zeroage Metric: 10.00 / 13 (76.9%):  50%|███▌   | 12/24 [00:15<00:18,  1.55s/it]\n",
      "zero\n",
      "zeroage Metric: 11.00 / 14 (78.6%):  58%|████   | 14/24 [00:17<00:11,  1.14s/it]\n",
      "zero\n",
      "externalMetric: 12.00 / 15 (80.0%):  62%|████▍  | 15/24 [00:18<00:09,  1.09s/it]\n",
      "internal\n",
      "zeroage Metric: 12.00 / 16 (75.0%):  67%|████▋  | 16/24 [00:18<00:07,  1.10it/s]\n",
      "internal\n",
      "zeroage Metric: 12.00 / 17 (70.6%):  71%|████▉  | 17/24 [00:18<00:05,  1.26it/s]\n",
      "zero\n",
      "externalMetric: 13.00 / 18 (72.2%):  75%|█████▎ | 18/24 [00:19<00:03,  1.56it/s]\n",
      "zero\n",
      "zeroage Metric: 13.00 / 19 (68.4%):  79%|█████▌ | 19/24 [00:20<00:03,  1.35it/s]\n",
      "zero\n",
      "externalMetric: 14.00 / 20 (70.0%):  83%|█████▊ | 20/24 [00:21<00:03,  1.25it/s]\n",
      "internal\n",
      "externalMetric: 14.00 / 21 (66.7%):  88%|██████▏| 21/24 [00:22<00:02,  1.09it/s]\n",
      "zero\n",
      "internalMetric: 14.00 / 22 (63.6%):  92%|██████▍| 22/24 [00:23<00:02,  1.05s/it]\n",
      "internal\n",
      "externalMetric: 15.00 / 23 (65.2%):  96%|██████▋| 23/24 [00:24<00:00,  1.18it/s]\n",
      "zero\n",
      "Average Metric: 15.00 / 24 (62.5%): 100%|███████| 24/24 [00:24<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/24 11:09:09 INFO dspy.evaluate.evaluate: Average Metric: 15 / 24 (62.5%)\n",
      "2025/04/24 11:09:09 INFO dspy.teleprompt.copro_optimizer: At Depth 1/3, Evaluating Prompt Candidate #2/4 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "internal                                                 | 0/24 [00:00<?, ?it/s]\n",
      "internal\n",
      "internalMetric: 1.00 / 1 (100.0%):   4%|▍        | 1/24 [00:02<01:05,  2.85s/it]\n",
      "internal\n",
      "internalMetric: 2.00 / 2 (100.0%):   8%|▊        | 2/24 [00:03<00:31,  1.42s/it]\n",
      "internal\n",
      "zeroage Metric: 3.00 / 3 (100.0%):   8%|▊        | 2/24 [00:03<00:31,  1.42s/it]\n",
      "zero\n",
      "externalMetric: 4.00 / 4 (100.0%):  17%|█▌       | 4/24 [00:03<00:11,  1.72it/s]\n",
      "zero\n",
      "externalMetric: 4.00 / 5 (80.0%):  21%|██        | 5/24 [00:03<00:10,  1.78it/s]\n",
      "zero\n",
      "zeroage Metric: 4.00 / 6 (66.7%):  25%|██▌       | 6/24 [00:06<00:22,  1.25s/it]\n",
      "zero\n",
      "zeroage Metric: 5.00 / 7 (71.4%):  29%|██▉       | 7/24 [00:06<00:15,  1.10it/s]\n",
      "zero\n",
      "externalMetric: 6.00 / 8 (75.0%):  33%|███▎      | 8/24 [00:07<00:13,  1.19it/s]\n",
      "zero\n",
      "internalMetric: 6.00 / 9 (66.7%):  33%|███▎      | 8/24 [00:07<00:13,  1.19it/s]\n",
      "internal\n",
      "internalMetric: 7.00 / 10 (70.0%):  42%|███▎    | 10/24 [00:07<00:06,  2.11it/s]\n",
      "internal\n",
      "internalMetric: 8.00 / 11 (72.7%):  46%|███▋    | 11/24 [00:09<00:09,  1.31it/s]\n",
      "internal\n",
      "internalMetric: 9.00 / 12 (75.0%):  50%|████    | 12/24 [00:12<00:17,  1.45s/it]\n",
      "internal\n",
      "zeroage Metric: 10.00 / 13 (76.9%):  54%|███▊   | 13/24 [00:14<00:16,  1.47s/it]\n",
      "zero\n",
      "zeroage Metric: 11.00 / 14 (78.6%):  54%|███▊   | 13/24 [00:14<00:16,  1.47s/it]\n",
      "zero\n",
      "zeroage Metric: 12.00 / 15 (80.0%):  62%|████▍  | 15/24 [00:14<00:08,  1.03it/s]\n",
      "internal\n",
      "externalMetric: 12.00 / 16 (75.0%):  67%|████▋  | 16/24 [00:15<00:06,  1.22it/s]\n",
      "internal\n",
      "externalMetric: 12.00 / 17 (70.6%):  71%|████▉  | 17/24 [00:15<00:05,  1.39it/s]\n",
      "zero\n",
      "zeroage Metric: 12.00 / 18 (66.7%):  75%|█████▎ | 18/24 [00:17<00:05,  1.09it/s]\n",
      "zero\n",
      "externalMetric: 13.00 / 19 (68.4%):  75%|█████▎ | 18/24 [00:17<00:05,  1.09it/s]\n",
      "zero\n",
      "zeroage Metric: 13.00 / 20 (65.0%):  83%|█████▊ | 20/24 [00:19<00:04,  1.05s/it]\n",
      "zero\n",
      "externalMetric: 14.00 / 21 (66.7%):  88%|██████▏| 21/24 [00:20<00:03,  1.02s/it]\n",
      "internal\n",
      "externalMetric: 14.00 / 22 (63.6%):  92%|██████▍| 22/24 [00:21<00:01,  1.01it/s]\n",
      "zero\n",
      "internalMetric: 14.00 / 23 (60.9%):  96%|██████▋| 23/24 [00:21<00:00,  1.26it/s]\n",
      "zero\n",
      "Average Metric: 14.00 / 24 (58.3%): 100%|███████| 24/24 [00:23<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/24 11:09:33 INFO dspy.evaluate.evaluate: Average Metric: 14 / 24 (58.3%)\n",
      "2025/04/24 11:09:33 INFO dspy.teleprompt.copro_optimizer: At Depth 1/3, Evaluating Prompt Candidate #3/4 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "internal                                                 | 0/24 [00:00<?, ?it/s]\n",
      "internal\n",
      "internalMetric: 1.00 / 1 (100.0%):   4%|▍        | 1/24 [00:03<01:11,  3.11s/it]\n",
      "internal\n",
      "internalMetric: 2.00 / 2 (100.0%):   8%|▊        | 2/24 [00:03<00:35,  1.61s/it]\n",
      "internal\n",
      "zeroage Metric: 3.00 / 3 (100.0%):  12%|█▏       | 3/24 [00:04<00:24,  1.19s/it]\n",
      "zero\n",
      "externalMetric: 4.00 / 4 (100.0%):  17%|█▌       | 4/24 [00:05<00:22,  1.12s/it]\n",
      "zero\n",
      "externalMetric: 4.00 / 5 (80.0%):  21%|██        | 5/24 [00:07<00:28,  1.52s/it]\n",
      "internal\n",
      "zeroage Metric: 4.00 / 6 (66.7%):  25%|██▌       | 6/24 [00:07<00:19,  1.07s/it]\n",
      "zero\n",
      "externalMetric: 5.00 / 7 (71.4%):  29%|██▉       | 7/24 [00:09<00:21,  1.26s/it]\n",
      "zero\n",
      "zeroage Metric: 5.00 / 8 (62.5%):  33%|███▎      | 8/24 [00:09<00:14,  1.09it/s]\n",
      "zero\n",
      "internalMetric: 6.00 / 9 (66.7%):  38%|███▊      | 9/24 [00:11<00:17,  1.14s/it]\n",
      "internal\n",
      "internalMetric: 7.00 / 10 (70.0%):  42%|███▎    | 10/24 [00:11<00:11,  1.21it/s]\n",
      "zero\n",
      "internalMetric: 7.00 / 11 (63.6%):  46%|███▋    | 11/24 [00:13<00:14,  1.12s/it]\n",
      "internal\n",
      "internalMetric: 8.00 / 12 (66.7%):  46%|███▋    | 11/24 [00:13<00:14,  1.12s/it]\n",
      "internal\n",
      "zeroage Metric: 9.00 / 13 (69.2%):  54%|████▎   | 13/24 [00:14<00:10,  1.00it/s]\n",
      "internal\n",
      "zeroage Metric: 9.00 / 14 (64.3%):  58%|████▋   | 14/24 [00:15<00:08,  1.15it/s]\n",
      "internal\n",
      "externalMetric: 9.00 / 15 (60.0%):  62%|█████   | 15/24 [00:16<00:07,  1.14it/s]\n",
      "internal\n",
      "zeroage Metric: 9.00 / 16 (56.2%):  62%|█████   | 15/24 [00:16<00:07,  1.14it/s]\n",
      "internal\n",
      "zeroage Metric: 9.00 / 17 (52.9%):  71%|█████▋  | 17/24 [00:16<00:03,  1.83it/s]\n",
      "zero\n",
      "externalMetric: 10.00 / 18 (55.6%):  75%|█████▎ | 18/24 [00:18<00:05,  1.07it/s]\n",
      "external\n",
      "zeroage Metric: 11.00 / 19 (57.9%):  79%|█████▌ | 19/24 [00:18<00:03,  1.37it/s]\n",
      "zero\n",
      "externalMetric: 12.00 / 20 (60.0%):  83%|█████▊ | 20/24 [00:21<00:04,  1.14s/it]\n",
      "internal\n",
      "externalMetric: 12.00 / 21 (57.1%):  88%|██████▏| 21/24 [00:22<00:03,  1.19s/it]\n",
      "zero\n",
      "externalMetric: 12.00 / 22 (54.5%):  92%|██████▍| 22/24 [00:23<00:02,  1.28s/it]\n",
      "zero\n",
      "internalMetric: 12.00 / 23 (52.2%):  96%|██████▋| 23/24 [00:24<00:01,  1.07s/it]\n",
      "internal\n",
      "Average Metric: 13.00 / 24 (54.2%): 100%|███████| 24/24 [00:27<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/24 11:10:01 INFO dspy.evaluate.evaluate: Average Metric: 13 / 24 (54.2%)\n",
      "2025/04/24 11:10:01 INFO dspy.teleprompt.copro_optimizer: At Depth 1/3, Evaluating Prompt Candidate #4/4 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "external\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "external\n",
      "zero\n",
      "external\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "external\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "external\n",
      "external\n",
      "zero\n",
      "zero\n",
      "external\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "external\n",
      "internal\n",
      "external\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "Average Metric: 14.00 / 24 (58.3%): 100%|█████| 24/24 [00:00<00:00, 4044.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/24 11:10:01 INFO dspy.evaluate.evaluate: Average Metric: 14 / 24 (58.3%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/24 11:10:05 INFO dspy.teleprompt.copro_optimizer: Iteration Depth: 2/3.\n",
      "2025/04/24 11:10:05 INFO dspy.teleprompt.copro_optimizer: At Depth 2/3, Evaluating Prompt Candidate #1/4 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "internal                                                 | 0/24 [00:00<?, ?it/s]\n",
      "internal\n",
      "internalMetric: 1.00 / 1 (100.0%):   4%|▍        | 1/24 [00:02<00:56,  2.45s/it]\n",
      "internal\n",
      "internalMetric: 2.00 / 2 (100.0%):   4%|▍        | 1/24 [00:02<00:56,  2.45s/it]\n",
      "internal\n",
      "zeroage Metric: 3.00 / 3 (100.0%):  12%|█▏       | 3/24 [00:03<00:19,  1.07it/s]\n",
      "zero\n",
      "externalMetric: 4.00 / 4 (100.0%):  17%|█▌       | 4/24 [00:03<00:14,  1.37it/s]\n",
      "zero\n",
      "externalMetric: 4.00 / 5 (80.0%):  21%|██        | 5/24 [00:04<00:14,  1.35it/s]\n",
      "external\n",
      "zeroage Metric: 5.00 / 6 (83.3%):  25%|██▌       | 6/24 [00:05<00:13,  1.35it/s]\n",
      "zero\n",
      "internalMetric: 6.00 / 7 (85.7%):  29%|██▉       | 7/24 [00:05<00:10,  1.57it/s]\n",
      "internal\n",
      "externalMetric: 7.00 / 8 (87.5%):  33%|███▎      | 8/24 [00:06<00:13,  1.22it/s]\n",
      "zero\n",
      "zeroage Metric: 7.00 / 9 (77.8%):  38%|███▊      | 9/24 [00:07<00:09,  1.51it/s]\n",
      "zero\n",
      "internalMetric: 8.00 / 10 (80.0%):  42%|███▎    | 10/24 [00:08<00:13,  1.04it/s]\n",
      "internal\n",
      "zeroage Metric: 9.00 / 11 (81.8%):  46%|███▋    | 11/24 [00:09<00:10,  1.21it/s]\n",
      "internal\n",
      "Average Metric: 9.00 / 12 (75.0%):  50%|████    | 12/24 [00:09<00:09,  1.31it/s]\n",
      "internal\n",
      "internalMetric: 9.00 / 13 (69.2%):  50%|████    | 12/24 [00:09<00:09,  1.31it/s]\n",
      "internal\n",
      "internalMetric: 10.00 / 14 (71.4%):  58%|████   | 14/24 [00:10<00:04,  2.08it/s]\n",
      "internal\n",
      "externalMetric: 11.00 / 15 (73.3%):  62%|████▍  | 15/24 [00:11<00:07,  1.26it/s]\n",
      "internal\n",
      "zeroage Metric: 11.00 / 16 (68.8%):  67%|████▋  | 16/24 [00:11<00:04,  1.63it/s]\n",
      "internal\n",
      "zeroage Metric: 11.00 / 17 (64.7%):  71%|████▉  | 17/24 [00:12<00:03,  1.95it/s]\n",
      "zero\n",
      "zeroage Metric: 12.00 / 18 (66.7%):  75%|█████▎ | 18/24 [00:13<00:03,  1.63it/s]\n",
      "zero\n",
      "externalMetric: 13.00 / 19 (68.4%):  79%|█████▌ | 19/24 [00:14<00:03,  1.29it/s]\n",
      "zero\n",
      "externalMetric: 13.00 / 20 (65.0%):  79%|█████▌ | 19/24 [00:14<00:03,  1.29it/s]\n",
      "internal\n",
      "externalMetric: 13.00 / 21 (61.9%):  88%|██████▏| 21/24 [00:14<00:01,  2.10it/s]\n",
      "external\n",
      "internalMetric: 14.00 / 22 (63.6%):  92%|██████▍| 22/24 [00:14<00:00,  2.34it/s]\n",
      "internal\n",
      "externalMetric: 15.00 / 23 (65.2%):  96%|██████▋| 23/24 [00:15<00:00,  2.30it/s]\n",
      "zero\n",
      "Average Metric: 15.00 / 24 (62.5%): 100%|███████| 24/24 [00:17<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/24 11:10:23 INFO dspy.evaluate.evaluate: Average Metric: 15 / 24 (62.5%)\n",
      "2025/04/24 11:10:23 INFO dspy.teleprompt.copro_optimizer: At Depth 2/3, Evaluating Prompt Candidate #2/4 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "internal                                                 | 0/24 [00:00<?, ?it/s]\n",
      "internal\n",
      "internalMetric: 1.00 / 1 (100.0%):   4%|▍        | 1/24 [00:03<01:17,  3.38s/it]\n",
      "internal\n",
      "internalMetric: 2.00 / 2 (100.0%):   8%|▊        | 2/24 [00:03<00:33,  1.52s/it]\n",
      "internal\n",
      "zeroage Metric: 3.00 / 3 (100.0%):  12%|█▏       | 3/24 [00:03<00:19,  1.08it/s]\n",
      "zero\n",
      "externalMetric: 4.00 / 4 (100.0%):  12%|█▏       | 3/24 [00:03<00:19,  1.08it/s]\n",
      "internal\n",
      "externalMetric: 4.00 / 5 (80.0%):  21%|██        | 5/24 [00:04<00:10,  1.83it/s]\n",
      "zero\n",
      "zeroage Metric: 4.00 / 6 (66.7%):  25%|██▌       | 6/24 [00:06<00:19,  1.09s/it]\n",
      "zero\n",
      "internalMetric: 5.00 / 7 (71.4%):  25%|██▌       | 6/24 [00:06<00:19,  1.09s/it]\n",
      "internal\n",
      "externalMetric: 6.00 / 8 (75.0%):  33%|███▎      | 8/24 [00:06<00:10,  1.57it/s]\n",
      "zero\n",
      "zeroage Metric: 6.00 / 9 (66.7%):  38%|███▊      | 9/24 [00:08<00:11,  1.30it/s]\n",
      "zero\n",
      "internalMetric: 7.00 / 10 (70.0%):  42%|███▎    | 10/24 [00:08<00:10,  1.32it/s]\n",
      "internal\n",
      "internalMetric: 8.00 / 11 (72.7%):  46%|███▋    | 11/24 [00:10<00:12,  1.03it/s]\n",
      "internal\n",
      "zeroage Metric: 9.00 / 12 (75.0%):  50%|████    | 12/24 [00:10<00:08,  1.36it/s]\n",
      "zero\n",
      "internalMetric: 10.00 / 13 (76.9%):  54%|███▊   | 13/24 [00:10<00:06,  1.65it/s]\n",
      "internal\n",
      "externalMetric: 11.00 / 14 (78.6%):  58%|████   | 14/24 [00:11<00:05,  1.73it/s]\n",
      "external\n",
      "zeroage Metric: 12.00 / 15 (80.0%):  62%|████▍  | 15/24 [00:13<00:09,  1.06s/it]\n",
      "zero\n",
      "externalMetric: 13.00 / 16 (81.2%):  62%|████▍  | 15/24 [00:13<00:09,  1.06s/it]\n",
      "internal\n",
      "zeroage Metric: 13.00 / 17 (76.5%):  71%|████▉  | 17/24 [00:14<00:04,  1.42it/s]\n",
      "internal\n",
      "zeroage Metric: 13.00 / 18 (72.2%):  71%|████▉  | 17/24 [00:14<00:04,  1.42it/s]\n",
      "internal\n",
      "zeroage Metric: 13.00 / 19 (68.4%):  75%|█████▎ | 18/24 [00:14<00:03,  1.78it/s]\n",
      "zero\n",
      "externalMetric: 14.00 / 20 (70.0%):  83%|█████▊ | 20/24 [00:16<00:03,  1.23it/s]\n",
      "internal\n",
      "externalMetric: 14.00 / 21 (66.7%):  88%|██████▏| 21/24 [00:16<00:02,  1.38it/s]\n",
      "external\n",
      "internalMetric: 15.00 / 22 (68.2%):  92%|██████▍| 22/24 [00:18<00:01,  1.05it/s]\n",
      "internal\n",
      "externalMetric: 16.00 / 23 (69.6%):  96%|██████▋| 23/24 [00:18<00:00,  1.25it/s]\n",
      "zero\n",
      "Average Metric: 16.00 / 24 (66.7%): 100%|███████| 24/24 [00:19<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/24 11:10:42 INFO dspy.evaluate.evaluate: Average Metric: 16 / 24 (66.7%)\n",
      "2025/04/24 11:10:42 INFO dspy.teleprompt.copro_optimizer: At Depth 2/3, Evaluating Prompt Candidate #3/4 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "internal                                                 | 0/24 [00:00<?, ?it/s]\n",
      "internal\n",
      "zeroage Metric: 1.00 / 1 (100.0%):   4%|▍        | 1/24 [00:02<00:53,  2.32s/it]\n",
      "zero\n",
      "internalMetric: 2.00 / 2 (100.0%):   8%|▊        | 2/24 [00:03<00:39,  1.81s/it]\n",
      "internal\n",
      "externalMetric: 3.00 / 3 (100.0%):  12%|█▏       | 3/24 [00:05<00:38,  1.82s/it]\n",
      "zero\n",
      "externalMetric: 3.00 / 4 (75.0%):  17%|█▋        | 4/24 [00:05<00:23,  1.19s/it]\n",
      "internal\n",
      "zeroage Metric: 3.00 / 5 (60.0%):  21%|██        | 5/24 [00:06<00:17,  1.11it/s]\n",
      "zero\n",
      "internalMetric: 4.00 / 6 (66.7%):  25%|██▌       | 6/24 [00:07<00:15,  1.14it/s]\n",
      "internal\n",
      "externalMetric: 5.00 / 7 (71.4%):  29%|██▉       | 7/24 [00:07<00:13,  1.21it/s]\n",
      "zero\n",
      "zeroage Metric: 5.00 / 8 (62.5%):  33%|███▎      | 8/24 [00:09<00:15,  1.01it/s]\n",
      "zero\n",
      "internalMetric: 6.00 / 9 (66.7%):  38%|███▊      | 9/24 [00:09<00:12,  1.20it/s]\n",
      "internal\n",
      "internalMetric: 7.00 / 10 (70.0%):  42%|███▎    | 10/24 [00:09<00:09,  1.48it/s]\n",
      "internal\n",
      "internalMetric: 8.00 / 11 (72.7%):  46%|███▋    | 11/24 [00:10<00:07,  1.71it/s]\n",
      "internal\n",
      "zeroage Metric: 9.00 / 12 (75.0%):  50%|████    | 12/24 [00:12<00:11,  1.03it/s]\n",
      "internal\n",
      "zeroage Metric: 9.00 / 13 (69.2%):  54%|████▎   | 13/24 [00:14<00:15,  1.40s/it]\n",
      "internal\n",
      "internalMetric: 9.00 / 14 (64.3%):  58%|████▋   | 14/24 [00:15<00:12,  1.22s/it]\n",
      "zero\n",
      "zeroage Metric: 9.00 / 15 (60.0%):  58%|████▋   | 14/24 [00:15<00:12,  1.22s/it]\n",
      "zero\n",
      "externalMetric: 10.00 / 16 (62.5%):  67%|████▋  | 16/24 [00:15<00:05,  1.41it/s]\n",
      "external\n",
      "externalMetric: 11.00 / 17 (64.7%):  71%|████▉  | 17/24 [00:17<00:07,  1.01s/it]\n",
      "internal\n",
      "zeroage Metric: 11.00 / 18 (61.1%):  75%|█████▎ | 18/24 [00:17<00:04,  1.27it/s]\n",
      "zero\n",
      "externalMetric: 12.00 / 19 (63.2%):  79%|█████▌ | 19/24 [00:17<00:03,  1.51it/s]\n",
      "internal\n",
      "externalMetric: 12.00 / 20 (60.0%):  83%|█████▊ | 20/24 [00:19<00:03,  1.12it/s]\n",
      "zero\n",
      "externalMetric: 12.00 / 21 (57.1%):  88%|██████▏| 21/24 [00:19<00:02,  1.42it/s]\n",
      "zero\n",
      "internalMetric: 12.00 / 22 (54.5%):  92%|██████▍| 22/24 [00:20<00:01,  1.40it/s]\n",
      "internal\n",
      "zeroage Metric: 13.00 / 23 (56.5%):  96%|██████▋| 23/24 [00:24<00:01,  1.64s/it]\n",
      "zero\n",
      "Average Metric: 14.00 / 24 (58.3%): 100%|███████| 24/24 [00:35<00:00,  1.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/24 11:11:17 INFO dspy.evaluate.evaluate: Average Metric: 14 / 24 (58.3%)\n",
      "2025/04/24 11:11:17 INFO dspy.teleprompt.copro_optimizer: At Depth 2/3, Evaluating Prompt Candidate #4/4 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "internal                                                 | 0/24 [00:00<?, ?it/s]\n",
      "internal\n",
      "internalMetric: 1.00 / 1 (100.0%):   4%|▍        | 1/24 [00:02<00:56,  2.44s/it]\n",
      "internal\n",
      "internalMetric: 2.00 / 2 (100.0%):   8%|▊        | 2/24 [00:02<00:27,  1.24s/it]\n",
      "internal\n",
      "externalMetric: 3.00 / 3 (100.0%):   8%|▊        | 2/24 [00:02<00:27,  1.24s/it]\n",
      "zero\n",
      "externalMetric: 3.00 / 4 (75.0%):  17%|█▋        | 4/24 [00:03<00:14,  1.38it/s]\n",
      "external\n",
      "zeroage Metric: 4.00 / 5 (80.0%):  21%|██        | 5/24 [00:05<00:18,  1.01it/s]\n",
      "zero\n",
      "internalMetric: 5.00 / 6 (83.3%):  25%|██▌       | 6/24 [00:05<00:14,  1.23it/s]\n",
      "internal\n",
      "zeroage Metric: 6.00 / 7 (85.7%):  29%|██▉       | 7/24 [00:07<00:19,  1.14s/it]\n",
      "zero\n",
      "externalMetric: 7.00 / 8 (87.5%):  29%|██▉       | 7/24 [00:07<00:19,  1.14s/it]\n",
      "zero\n",
      "zeroage Metric: 7.00 / 9 (77.8%):  38%|███▊      | 9/24 [00:08<00:11,  1.25it/s]\n",
      "zero\n",
      "internalMetric: 8.00 / 10 (80.0%):  42%|███▎    | 10/24 [00:08<00:09,  1.50it/s]\n",
      "zero\n",
      "internalMetric: 8.00 / 11 (72.7%):  46%|███▋    | 11/24 [00:11<00:15,  1.17s/it]\n",
      "internal\n",
      "internalMetric: 9.00 / 12 (75.0%):  50%|████    | 12/24 [00:11<00:10,  1.10it/s]\n",
      "internal\n",
      "zeroage Metric: 10.00 / 13 (76.9%):  54%|███▊   | 13/24 [00:11<00:07,  1.42it/s]\n",
      "internal\n",
      "zeroage Metric: 10.00 / 14 (71.4%):  58%|████   | 14/24 [00:11<00:05,  1.83it/s]\n",
      "zero\n",
      "zeroage Metric: 11.00 / 15 (73.3%):  62%|████▍  | 15/24 [00:12<00:05,  1.69it/s]\n",
      "zero\n",
      "externalMetric: 12.00 / 16 (75.0%):  67%|████▋  | 16/24 [00:14<00:08,  1.08s/it]\n",
      "external\n",
      "externalMetric: 13.00 / 17 (76.5%):  71%|████▉  | 17/24 [00:14<00:05,  1.22it/s]\n",
      "internal\n",
      "zeroage Metric: 13.00 / 18 (72.2%):  75%|█████▎ | 18/24 [00:15<00:04,  1.37it/s]\n",
      "zero\n",
      "internalMetric: 14.00 / 19 (73.7%):  79%|█████▌ | 19/24 [00:15<00:03,  1.53it/s]\n",
      "internal\n",
      "zeroage Metric: 15.00 / 20 (75.0%):  83%|█████▊ | 20/24 [00:17<00:03,  1.14it/s]\n",
      "zero\n",
      "externalMetric: 16.00 / 21 (76.2%):  88%|██████▏| 21/24 [00:17<00:01,  1.52it/s]\n",
      "external\n",
      "externalMetric: 17.00 / 22 (77.3%):  92%|██████▍| 22/24 [00:18<00:01,  1.51it/s]\n",
      "zero\n",
      "externalMetric: 17.00 / 23 (73.9%):  96%|██████▋| 23/24 [00:19<00:00,  1.22it/s]\n",
      "internal\n",
      "Average Metric: 17.00 / 24 (70.8%): 100%|███████| 24/24 [00:19<00:00,  1.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/24 11:11:37 INFO dspy.evaluate.evaluate: Average Metric: 17 / 24 (70.8%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/24 11:11:46 INFO dspy.teleprompt.copro_optimizer: Iteration Depth: 3/3.\n",
      "2025/04/24 11:11:46 INFO dspy.teleprompt.copro_optimizer: At Depth 3/3, Evaluating Prompt Candidate #1/4 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero|                                                    | 0/24 [00:00<?, ?it/s]\n",
      "zero\n",
      "internalMetric: 1.00 / 1 (100.0%):   4%|▍        | 1/24 [00:03<01:15,  3.30s/it]\n",
      "external\n",
      "internalMetric: 1.00 / 2 (50.0%):   4%|▍         | 1/24 [00:03<01:15,  3.30s/it]\n",
      "internal\n",
      "internalMetric: 2.00 / 3 (66.7%):  12%|█▎        | 3/24 [00:04<00:26,  1.26s/it]\n",
      "internal\n",
      "externalMetric: 3.00 / 4 (75.0%):  12%|█▎        | 3/24 [00:04<00:26,  1.26s/it]\n",
      "external\n",
      "externalMetric: 4.00 / 5 (80.0%):  21%|██        | 5/24 [00:05<00:16,  1.13it/s]\n",
      "zero\n",
      "zeroage Metric: 4.00 / 6 (66.7%):  25%|██▌       | 6/24 [00:05<00:12,  1.45it/s]\n",
      "zero\n",
      "internalMetric: 5.00 / 7 (71.4%):  29%|██▉       | 7/24 [00:06<00:13,  1.28it/s]\n",
      "internal\n",
      "zeroage Metric: 6.00 / 8 (75.0%):  33%|███▎      | 8/24 [00:07<00:13,  1.17it/s]\n",
      "zero\n",
      "externalMetric: 7.00 / 9 (77.8%):  33%|███▎      | 8/24 [00:07<00:13,  1.17it/s]\n",
      "zero\n",
      "internalMetric: 7.00 / 10 (70.0%):  42%|███▎    | 10/24 [00:09<00:11,  1.22it/s]\n",
      "internal\n",
      "zeroage Metric: 8.00 / 11 (72.7%):  46%|███▋    | 11/24 [00:10<00:11,  1.10it/s]\n",
      "internal\n",
      "internalMetric: 8.00 / 12 (66.7%):  50%|████    | 12/24 [00:10<00:08,  1.34it/s]\n",
      "internal\n",
      "zeroage Metric: 9.00 / 13 (69.2%):  54%|████▎   | 13/24 [00:12<00:09,  1.10it/s]\n",
      "zero\n",
      "zeroage Metric: 10.00 / 14 (71.4%):  58%|████   | 14/24 [00:12<00:07,  1.30it/s]\n",
      "internal\n",
      "internalMetric: 10.00 / 15 (66.7%):  62%|████▍  | 15/24 [00:12<00:05,  1.62it/s]\n",
      "internal\n",
      "externalMetric: 11.00 / 16 (68.8%):  62%|████▍  | 15/24 [00:12<00:05,  1.62it/s]\n",
      "external\n",
      "zeroage Metric: 12.00 / 17 (70.6%):  71%|████▉  | 17/24 [00:14<00:04,  1.44it/s]\n",
      "zero\n",
      "externalMetric: 13.00 / 18 (72.2%):  75%|█████▎ | 18/24 [00:14<00:03,  1.78it/s]\n",
      "internal\n",
      "externalMetric: 13.00 / 19 (68.4%):  79%|█████▌ | 19/24 [00:16<00:04,  1.18it/s]\n",
      "zero\n",
      "zeroage Metric: 13.00 / 20 (65.0%):  83%|█████▊ | 20/24 [00:16<00:03,  1.33it/s]\n",
      "zero\n",
      "internalMetric: 14.00 / 21 (66.7%):  88%|██████▏| 21/24 [00:17<00:02,  1.43it/s]\n",
      "internal\n",
      "externalMetric: 15.00 / 22 (68.2%):  92%|██████▍| 22/24 [00:17<00:01,  1.86it/s]\n",
      "internal\n",
      "externalMetric: 15.00 / 23 (65.2%):  96%|██████▋| 23/24 [00:17<00:00,  2.27it/s]\n",
      "zero\n",
      "Average Metric: 15.00 / 24 (62.5%): 100%|███████| 24/24 [00:18<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/24 11:12:05 INFO dspy.evaluate.evaluate: Average Metric: 15 / 24 (62.5%)\n",
      "2025/04/24 11:12:05 INFO dspy.teleprompt.copro_optimizer: At Depth 3/3, Evaluating Prompt Candidate #2/4 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "external                                                 | 0/24 [00:00<?, ?it/s]\n",
      "internal\n",
      "internalMetric: 0.00 / 1 (0.0%):   4%|▍          | 1/24 [00:01<00:45,  2.00s/it]\n",
      "internal\n",
      "internalMetric: 1.00 / 2 (50.0%):   4%|▍         | 1/24 [00:02<00:45,  2.00s/it]\n",
      "internal\n",
      "externalMetric: 2.00 / 3 (66.7%):  12%|█▎        | 3/24 [00:03<00:26,  1.25s/it]\n",
      "external\n",
      "internalMetric: 3.00 / 4 (75.0%):  17%|█▋        | 4/24 [00:04<00:18,  1.07it/s]\n",
      "internal\n",
      "zeroage Metric: 4.00 / 5 (80.0%):  21%|██        | 5/24 [00:04<00:12,  1.49it/s]\n",
      "zero\n",
      "zeroage Metric: 5.00 / 6 (83.3%):  21%|██        | 5/24 [00:04<00:12,  1.49it/s]\n",
      "zero\n",
      "zeroage Metric: 6.00 / 7 (85.7%):  29%|██▉       | 7/24 [00:05<00:09,  1.86it/s]\n",
      "zero\n",
      "internalMetric: 7.00 / 8 (87.5%):  33%|███▎      | 8/24 [00:06<00:12,  1.26it/s]\n",
      "internal\n",
      "externalMetric: 8.00 / 9 (88.9%):  33%|███▎      | 8/24 [00:06<00:12,  1.26it/s]\n",
      "zero\n",
      "internalMetric: 8.00 / 10 (80.0%):  38%|███▍     | 9/24 [00:06<00:11,  1.26it/s]\n",
      "internal\n",
      "zeroage Metric: 9.00 / 11 (81.8%):  42%|███▎    | 10/24 [00:06<00:11,  1.26it/s]\n",
      "zero\n",
      "internalMetric: 10.00 / 12 (83.3%):  50%|███▌   | 12/24 [00:08<00:06,  1.92it/s]\n",
      "internal\n",
      "internalMetric: 11.00 / 13 (84.6%):  54%|███▊   | 13/24 [00:09<00:06,  1.64it/s]\n",
      "internal\n",
      "zeroage Metric: 12.00 / 14 (85.7%):  58%|████   | 14/24 [00:09<00:05,  1.83it/s]\n",
      "internal\n",
      "zeroage Metric: 12.00 / 15 (80.0%):  62%|████▍  | 15/24 [00:09<00:04,  2.02it/s]\n",
      "zero\n",
      "externalMetric: 13.00 / 16 (81.2%):  67%|████▋  | 16/24 [00:10<00:03,  2.03it/s]\n",
      "external\n",
      "zeroage Metric: 14.00 / 17 (82.4%):  71%|████▉  | 17/24 [00:11<00:04,  1.47it/s]\n",
      "zero\n",
      "externalMetric: 15.00 / 18 (83.3%):  75%|█████▎ | 18/24 [00:12<00:04,  1.29it/s]\n",
      "zero\n",
      "zeroage Metric: 15.00 / 19 (78.9%):  75%|█████▎ | 18/24 [00:12<00:04,  1.29it/s]\n",
      "zero\n",
      "internalMetric: 16.00 / 20 (80.0%):  83%|█████▊ | 20/24 [00:12<00:02,  1.89it/s]\n",
      "internal\n",
      "externalMetric: 17.00 / 21 (81.0%):  88%|██████▏| 21/24 [00:13<00:01,  1.55it/s]\n",
      "internal\n",
      "externalMetric: 17.00 / 22 (77.3%):  92%|██████▍| 22/24 [00:14<00:01,  1.81it/s]\n",
      "zero\n",
      "externalMetric: 17.00 / 23 (73.9%):  96%|██████▋| 23/24 [00:15<00:00,  1.54it/s]\n",
      "internal\n",
      "Average Metric: 17.00 / 24 (70.8%): 100%|███████| 24/24 [00:15<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/24 11:12:20 INFO dspy.evaluate.evaluate: Average Metric: 17 / 24 (70.8%)\n",
      "2025/04/24 11:12:20 INFO dspy.teleprompt.copro_optimizer: At Depth 3/3, Evaluating Prompt Candidate #3/4 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "external                                                 | 0/24 [00:00<?, ?it/s]\n",
      "external\n",
      "internalMetric: 1.00 / 1 (100.0%):   4%|▍        | 1/24 [00:02<00:52,  2.30s/it]\n",
      "internal\n",
      "internalMetric: 2.00 / 2 (100.0%):   8%|▊        | 2/24 [00:02<00:27,  1.25s/it]\n",
      "internal\n",
      "externalMetric: 3.00 / 3 (100.0%):  12%|█▏       | 3/24 [00:03<00:25,  1.20s/it]\n",
      "external\n",
      "internalMetric: 4.00 / 4 (100.0%):  17%|█▌       | 4/24 [00:04<00:21,  1.07s/it]\n",
      "internal\n",
      "zeroage Metric: 5.00 / 5 (100.0%):  17%|█▌       | 4/24 [00:04<00:21,  1.07s/it]\n",
      "zero\n",
      "zeroage Metric: 6.00 / 6 (100.0%):  25%|██▎      | 6/24 [00:05<00:11,  1.61it/s]\n",
      "zero\n",
      "internalMetric: 7.00 / 7 (100.0%):  29%|██▋      | 7/24 [00:05<00:09,  1.86it/s]\n",
      "internal\n",
      "internalMetric: 8.00 / 8 (100.0%):  33%|███      | 8/24 [00:07<00:12,  1.25it/s]\n",
      "internal\n",
      "externalMetric: 9.00 / 9 (100.0%):  38%|███▍     | 9/24 [00:07<00:12,  1.22it/s]\n",
      "zero\n",
      "zeroage Metric: 9.00 / 10 (90.0%):  42%|███▎    | 10/24 [00:08<00:09,  1.55it/s]\n",
      "zero\n",
      "zeroage Metric: 10.00 / 11 (90.9%):  46%|███▏   | 11/24 [00:09<00:09,  1.33it/s]\n",
      "internal\n",
      "internalMetric: 10.00 / 12 (83.3%):  50%|███▌   | 12/24 [00:09<00:06,  1.73it/s]\n",
      "internal\n",
      "zeroage Metric: 11.00 / 13 (84.6%):  54%|███▊   | 13/24 [00:10<00:09,  1.19it/s]\n",
      "internal\n",
      "zeroage Metric: 11.00 / 14 (78.6%):  58%|████   | 14/24 [00:11<00:07,  1.43it/s]\n",
      "internal\n",
      "internalMetric: 11.00 / 15 (73.3%):  62%|████▍  | 15/24 [00:11<00:06,  1.41it/s]\n",
      "internal\n",
      "zeroage Metric: 12.00 / 16 (75.0%):  67%|████▋  | 16/24 [00:12<00:05,  1.34it/s]\n",
      "internal\n",
      "zeroage Metric: 12.00 / 17 (70.6%):  71%|████▉  | 17/24 [00:14<00:07,  1.14s/it]\n",
      "zero\n",
      "externalMetric: 13.00 / 18 (72.2%):  75%|█████▎ | 18/24 [00:14<00:05,  1.17it/s]\n",
      "external\n",
      "externalMetric: 14.00 / 19 (73.7%):  75%|█████▎ | 18/24 [00:14<00:05,  1.17it/s]\n",
      "internal\n",
      "externalMetric: 14.00 / 20 (70.0%):  83%|█████▊ | 20/24 [00:16<00:03,  1.23it/s]\n",
      "zero\n",
      "externalMetric: 14.00 / 21 (66.7%):  88%|██████▏| 21/24 [00:17<00:02,  1.11it/s]\n",
      "internal\n",
      "externalMetric: 14.00 / 22 (63.6%):  88%|██████▏| 21/24 [00:17<00:02,  1.11it/s]\n",
      "external\n",
      "internalMetric: 15.00 / 23 (65.2%):  96%|██████▋| 23/24 [00:18<00:00,  1.34it/s]\n",
      "internal\n",
      "Average Metric: 16.00 / 24 (66.7%): 100%|███████| 24/24 [00:18<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/24 11:12:39 INFO dspy.evaluate.evaluate: Average Metric: 16 / 24 (66.7%)\n",
      "2025/04/24 11:12:39 INFO dspy.teleprompt.copro_optimizer: At Depth 3/3, Evaluating Prompt Candidate #4/4 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "internal                                                 | 0/24 [00:00<?, ?it/s]\n",
      "internal\n",
      "internalMetric: 1.00 / 1 (100.0%):   4%|▍        | 1/24 [00:02<00:56,  2.46s/it]\n",
      "internal\n",
      "zeroage Metric: 2.00 / 2 (100.0%):   4%|▍        | 1/24 [00:02<00:56,  2.46s/it]\n",
      "zero\n",
      "externalMetric: 3.00 / 3 (100.0%):  12%|█▏       | 3/24 [00:03<00:20,  1.03it/s]\n",
      "zero\n",
      "externalMetric: 3.00 / 4 (75.0%):  17%|█▋        | 4/24 [00:03<00:14,  1.33it/s]\n",
      "external\n",
      "zeroage Metric: 4.00 / 5 (80.0%):  21%|██        | 5/24 [00:04<00:13,  1.44it/s]\n",
      "zero\n",
      "internalMetric: 5.00 / 6 (83.3%):  25%|██▌       | 6/24 [00:05<00:16,  1.06it/s]\n",
      "internal\n",
      "externalMetric: 6.00 / 7 (85.7%):  25%|██▌       | 6/24 [00:05<00:16,  1.06it/s]\n",
      "zero\n",
      "internalMetric: 6.00 / 8 (75.0%):  33%|███▎      | 8/24 [00:06<00:10,  1.59it/s]\n",
      "internal\n",
      "zeroage Metric: 7.00 / 9 (77.8%):  38%|███▊      | 9/24 [00:08<00:13,  1.08it/s]\n",
      "zero\n",
      "internalMetric: 8.00 / 10 (80.0%):  42%|███▎    | 10/24 [00:08<00:10,  1.37it/s]\n",
      "internal\n",
      "internalMetric: 9.00 / 11 (81.8%):  46%|███▋    | 11/24 [00:08<00:08,  1.50it/s]\n",
      "internal\n",
      "zeroage Metric: 10.00 / 12 (83.3%):  50%|███▌   | 12/24 [00:09<00:06,  1.87it/s]\n",
      "zero\n",
      "internalMetric: 11.00 / 13 (84.6%):  54%|███▊   | 13/24 [00:10<00:08,  1.30it/s]\n",
      "internal\n",
      "externalMetric: 12.00 / 14 (85.7%):  58%|████   | 14/24 [00:10<00:06,  1.55it/s]\n",
      "internal\n",
      "zeroage Metric: 12.00 / 15 (80.0%):  62%|████▍  | 15/24 [00:11<00:05,  1.60it/s]\n",
      "internal\n",
      "zeroage Metric: 12.00 / 16 (75.0%):  67%|████▋  | 16/24 [00:12<00:05,  1.46it/s]\n",
      "internal\n",
      "externalMetric: 12.00 / 17 (70.6%):  67%|████▋  | 16/24 [00:12<00:05,  1.46it/s]\n",
      "external\n",
      "externalMetric: 13.00 / 18 (72.2%):  75%|█████▎ | 18/24 [00:12<00:03,  1.75it/s]\n",
      "external\n",
      "zeroage Metric: 14.00 / 19 (73.7%):  79%|█████▌ | 19/24 [00:14<00:04,  1.16it/s]\n",
      "zero\n",
      "internalMetric: 15.00 / 20 (75.0%):  83%|█████▊ | 20/24 [00:14<00:02,  1.44it/s]\n",
      "internal\n",
      "externalMetric: 16.00 / 21 (76.2%):  83%|█████▊ | 20/24 [00:15<00:02,  1.44it/s]\n",
      "zero\n",
      "externalMetric: 16.00 / 22 (72.7%):  92%|██████▍| 22/24 [00:16<00:01,  1.42it/s]\n",
      "internal\n",
      "zeroage Metric: 16.00 / 23 (69.6%):  96%|██████▋| 23/24 [00:16<00:00,  1.66it/s]\n",
      "zero\n",
      "Average Metric: 17.00 / 24 (70.8%): 100%|███████| 24/24 [00:17<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/24 11:12:56 INFO dspy.evaluate.evaluate: Average Metric: 17 / 24 (70.8%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "kwargs = dict(num_threads=5, display_progress=True, display_table=0) # Used in Evaluate class in the optimization process\n",
    "compiled_prompt_opt = teleprompter.compile(DeterminacyPipe(), trainset=devset_with_input, eval_kwargs=kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bde0c190-6e17-4cec-b472-14e0c5aefb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictor.predict = Predict(StringSignature(text_snippet -> reasoning, tag\n",
       "    instructions='You will be given a sentence. Your task is to identify its mode of focalization by choosing one of the following labels: \"internal\", \"external\", or \"zero\". Use these definitions to guide your decision:\\n- Internal focalization: The sentence presents the world or events through the direct perspective, thoughts, or sensory experiences of a character involved in the scene.\\n- External focalization: The sentence depicts observable actions or perceptions that could be experienced by a character, but does not reveal any character’s inner thoughts, feelings, or explicit viewpoint.\\n- Zero focalization: The sentence provides information about the story world that is not accessible to any character’s perception or consciousness at the moment—such as omniscient narration, background facts, or events no character could witness in real time.\\n\\nCarefully analyze the sentence for clues about perspective, access to inner experience, and the scope of information presented. Output only the focalization label (\"internal\", \"external\", or \"zero\") on a single line, with no explanation.'\n",
       "    text_snippet = Field(annotation=str required=True json_schema_extra={'desc': 'contains a snippet of a narrative text', '__dspy_field_type': 'input', 'prefix': 'Text Snippet:'})\n",
       "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
       "    tag = Field(annotation=str required=True json_schema_extra={'desc': 'contains only the **label** in lower case', '__dspy_field_type': 'output', 'prefix': 'Focalization label:'})\n",
       "))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_prompt_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8979af3d-a142-41c0-8f09-8667b2506404",
   "metadata": {},
   "source": [
    "# Test with new Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e0cb6295-a5ed-467d-9ee3-75f2a7e1d06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "external\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "external\n",
      "external\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "external\n",
      "zero\n",
      "external\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "internal\n",
      "external\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "external\n",
      "zero\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "zero\n",
      "internal\n",
      "external\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "external\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "external\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "external\n",
      "external\n",
      "external\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "external\n",
      "zero\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "internal\n",
      "zero\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for text_snippet in df_anno_test.Absatz:\n",
    "    response = compiled_prompt_opt(text_snippet=text_snippet)\n",
    "    print(response.tag)\n",
    "    results.append(response.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a8ea4504-abd7-4f6c-879a-3af407fdcd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1 = []\n",
    "for text in results:\n",
    "    if \"internal focalization\" in text:\n",
    "        results_1.append(\"internal\")\n",
    "    elif \"internal\" in text:\n",
    "        results_1.append(\"internal\")\n",
    "    elif \"external focalization\" in text:\n",
    "        results_1.append(\"external\")\n",
    "    elif \"external\" in text:\n",
    "        results_1.append(\"external\")\n",
    "    elif \"zero focalization\" in text:\n",
    "        results_1.append(\"zero\")\n",
    "    elif \"zero\" in text:\n",
    "        results_1.append(\"zero\")\n",
    "    else:\n",
    "        results_1.append(\"NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "50b2eb51-65d8-4d05-8b4a-c38ffb8966da",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dspy = pd.Series(results_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bc35d167-eaa1-40ca-b31c-cfb0caf52823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          zero\n",
       "1          zero\n",
       "2      internal\n",
       "3          zero\n",
       "4      internal\n",
       "         ...   \n",
       "101    internal\n",
       "102    internal\n",
       "103    internal\n",
       "104    internal\n",
       "105        zero\n",
       "Length: 106, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b15cd1b2-3dd0-443a-8bcd-488328b152d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = df_anno_test.Fokalisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "914dbdc2-c555-4214-8877-c06bd7b6a7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          zero\n",
       "1          zero\n",
       "2      internal\n",
       "3          zero\n",
       "4      internal\n",
       "         ...   \n",
       "101    internal\n",
       "102    internal\n",
       "103    internal\n",
       "104    internal\n",
       "105    internal\n",
       "Name: Fokalisierung, Length: 106, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e7929c27-0865-4c77-8f3f-2a33c721fdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2aa04cdf-c247-4bd9-8a4b-f48a2d1a005d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.762909</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.763847</td>\n",
       "      <td>0.773585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         F1    Recall  Precision  Accuracy\n",
       "0  0.762909  0.773585   0.763847  0.773585"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip([f1_score(ground_truth, predictions_dspy, average=\"weighted\")],\n",
    "                      [recall_score(ground_truth, predictions_dspy,  average=\"weighted\")],\n",
    "                      [precision_score(ground_truth, predictions_dspy, average=\"weighted\")],\n",
    "                      [accuracy_score(ground_truth, predictions_dspy,)])),\n",
    "                      columns = [\"F1\", \"Recall\", \"Precision\", \"Accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9b7fa5b3-359b-4f35-a37d-299b623e5916",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_prompt_opt.save('gpt-41_dspied.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911c8d56-18b1-495b-a5bc-1b335efd348a",
   "metadata": {},
   "source": [
    "## Statistischer Test: McNemar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4aee1fa5-d3c1-459e-aefc-25e712ca645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from statsmodels.stats.contingency_tables import mcnemar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ce41e57a-e04d-494f-bc9e-4684c1b14312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Vergleichen der Vorhersagen mit dem Goldstandard\n",
    "def compare_with_gold(predictions, gold_standard):\n",
    "    return [pred == gold for pred, gold in zip(predictions, gold_standard)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "896e0eb8-7507-4362-80fc-5637bc88c99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Erstellen einer Kontingenztafel\n",
    "def create_contingency_table(results_a, results_b):\n",
    "    both_correct = sum(a and b for a, b in zip(results_a, results_b))\n",
    "    only_a_correct = sum(a and not b for a, b in zip(results_a, results_b))\n",
    "    only_b_correct = sum(b and not a for a, b in zip(results_a, results_b))\n",
    "    both_incorrect = sum(not a and not b for a, b in zip(results_a, results_b))\n",
    "    return np.array([[both_correct, only_a_correct],\n",
    "                     [only_b_correct, both_incorrect]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c5993e50-446d-436a-975b-3ed22bdb8274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# McNemar-Test durchführen\n",
    "def run_mcnemar_test(results_a, results_b):\n",
    "    table = create_contingency_table(results_a, results_b)\n",
    "    return mcnemar(table, exact=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8cd7a64b-e53d-4b23-803f-a698078abea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mcnemar_comparisons(\n",
    "    results_gpt4o,\n",
    "    df_anno,\n",
    "    num_templates=3,\n",
    "    runs=[1, 2],\n",
    "    optimized_predictions: Optional[pd.Series] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Führt McNemar-Vergleiche zwischen verschiedenen Prompt-Vorhersagen durch,\n",
    "    inklusive eines optionalen optimierten Prompts.\n",
    "\n",
    "    Args:\n",
    "        results_gpt4o: DataFrame mit Prediction-Spalten für alle Templates/Runs\n",
    "        df_anno: DataFrame mit Goldstandard ('Fokalisierung')\n",
    "        num_templates: Anzahl der verwendeten Template-Prompts\n",
    "        runs: Liste der Runs (z. B. [1, 2])\n",
    "        optimized_predictions: (optional) pd.Series mit Optimized-Prompt-Vorhersagen\n",
    "\n",
    "    Returns:\n",
    "        comparison_df: DataFrame mit allen McNemar-Test-Ergebnissen\n",
    "    \"\"\"\n",
    "    gold = df_anno[\"Fokalisierung\"]\n",
    "    comparison_results = []\n",
    "\n",
    "    for run in runs:\n",
    "        # Vorhersagen der Templates\n",
    "        predictions = {\n",
    "            f\"T{template_idx+1}\": compare_with_gold(\n",
    "                results_gpt4o[f\"Prediction_{template_idx}_Run{run}\"], gold\n",
    "            )\n",
    "            for template_idx in range(num_templates)\n",
    "        }\n",
    "\n",
    "        # Optional: Optimierten Prompt ergänzen\n",
    "        if optimized_predictions is not None:\n",
    "            predictions[\"Optimized\"] = compare_with_gold(optimized_predictions, gold)\n",
    "\n",
    "        # Paarweise Vergleiche\n",
    "        templates = list(predictions.keys())\n",
    "        for i in range(len(templates)):\n",
    "            for j in range(i + 1, len(templates)):\n",
    "                t1, t2 = templates[i], templates[j]\n",
    "                result = run_mcnemar_test(predictions[t1], predictions[t2])\n",
    "                comparison_results.append({\n",
    "                    \"Run\": run,\n",
    "                    \"Comparison\": f\"{t1} vs {t2}\",\n",
    "                    \"Prompt_A\": t1,\n",
    "                    \"Prompt_B\": t2,\n",
    "                    \"p-value\": result.pvalue\n",
    "                })\n",
    "\n",
    "    comparison_df = pd.DataFrame(comparison_results)\n",
    "    return comparison_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b197914b-7f65-47fd-9c7a-65c246e27322",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comparison_df = generate_mcnemar_comparisons(\n",
    "    results_gpt4o=results_gpt41,\n",
    "    df_anno=df_anno,\n",
    "    num_templates=3,\n",
    "    runs=[1, 2],\n",
    "    optimized_predictions=predictions_dspy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "41e66499-dec3-43f4-9e4c-ec8001ca8271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Run       Comparison Prompt_A   Prompt_B   p-value\n",
      "0     1         T1 vs T2       T1         T2  1.000000\n",
      "1     1         T1 vs T3       T1         T3  0.803619\n",
      "2     1  T1 vs Optimized       T1  Optimized  0.167068\n",
      "3     1         T2 vs T3       T2         T3  0.250000\n",
      "4     1  T2 vs Optimized       T2  Optimized  0.179565\n",
      "5     1  T3 vs Optimized       T3  Optimized  0.049042\n",
      "6     2         T1 vs T2       T1         T2  0.423950\n",
      "7     2         T1 vs T3       T1         T3  1.000000\n",
      "8     2  T1 vs Optimized       T1  Optimized  0.063568\n",
      "9     2         T2 vs T3       T2         T3  0.125000\n",
      "10    2  T2 vs Optimized       T2  Optimized  0.332306\n",
      "11    2  T3 vs Optimized       T3  Optimized  0.049042\n"
     ]
    }
   ],
   "source": [
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c259c9e8-2e11-4357-9b64-3483a92a9bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df.to_excel(\"mcnemar_vergleiche_gpt41.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f1febc4c-5c77-4f04-b631-0391d08a7ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_significant_comparisons(comparison_df, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Gibt alle Vergleichspaare mit p-Wert < alpha (standardmäßig 0.05) zurück.\n",
    "    \n",
    "    Args:\n",
    "        comparison_df: DataFrame mit den Spalten 'Run', 'Comparison', 'Prompt_A', 'Prompt_B', 'p-value'\n",
    "        alpha: Signifikanzniveau (Default: 0.05)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame mit nur signifikant unterschiedlichen Prompt-Paaren\n",
    "    \"\"\"\n",
    "    significant_df = comparison_df[comparison_df[\"p-value\"] < alpha].copy()\n",
    "    return significant_df.sort_values(by=[\"Run\", \"p-value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6893ba7d-2121-40e0-a777-8129dfe8b095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run</th>\n",
       "      <th>Comparison</th>\n",
       "      <th>Prompt_A</th>\n",
       "      <th>Prompt_B</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>T3 vs Optimized</td>\n",
       "      <td>T3</td>\n",
       "      <td>Optimized</td>\n",
       "      <td>0.049042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>T3 vs Optimized</td>\n",
       "      <td>T3</td>\n",
       "      <td>Optimized</td>\n",
       "      <td>0.049042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Run       Comparison Prompt_A   Prompt_B   p-value\n",
       "5     1  T3 vs Optimized       T3  Optimized  0.049042\n",
       "11    2  T3 vs Optimized       T3  Optimized  0.049042"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significant_comparisons = filter_significant_comparisons(comparison_df)\n",
    "significant_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515ad3ef-e68e-4050-9146-ec4add5bce49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
